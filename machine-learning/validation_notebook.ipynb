{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation notebook for running in Google Colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're using Google Colab and not running locally, run this cell.\n",
    "\n",
    "# Install dependencies\n",
    "!pip install wget\n",
    "!apt-get install sox libsndfile1 ffmpeg\n",
    "!pip install text-unidecode\n",
    "\n",
    "## Install NeMo\n",
    "BRANCH = 'main'\n",
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[asr]\n",
    "\n",
    "# Install TorchAudio\n",
    "!pip install torchaudio>=0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import glob\n",
    "import subprocess\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import nemo.collections.asr.models as nemo_asr_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Google Colab, mount your Google Drive to access the data\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio_file(input_file, output_file):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(input_file)\n",
    "\n",
    "    # Set the desired sample rate and channels\n",
    "    target_sample_rate = 16000\n",
    "    target_channels = 1\n",
    "\n",
    "    # Resample and set channels\n",
    "    audio = audio.set_frame_rate(target_sample_rate).set_channels(target_channels)\n",
    "\n",
    "    # Export the result as WAV\n",
    "    audio.export(output_file, format=\"wav\")\n",
    "\n",
    "def convert_volunteer_files():\n",
    "  NEMO_ROOT = os.getcwd()\n",
    "  data_dir = os.path.join(NEMO_ROOT,'data/volunteer_files_wav')\n",
    "  os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "  # Get the path to the folder containing the audio files\n",
    "  audio_folder_path = './data/volunteer_files'\n",
    "\n",
    "  # Get a list of all the audio files in the folder\n",
    "  audio_files = glob.glob(audio_folder_path + '/*')\n",
    "\n",
    "  # Read each audio file\n",
    "  for audio_file_path in audio_files:\n",
    "    file_name = audio_file_path[len(audio_folder_path):]\n",
    "    print('Converting: ' + file_name)\n",
    "    wav_path = data_dir + file_name[:-4] + '.wav'\n",
    "    convert_audio_file(audio_file_path, wav_path)\n",
    "\n",
    "  print(\"Finished conversion.\\n******\")\n",
    "\n",
    "def convert_validation_files():\n",
    "  NEMO_ROOT = os.getcwd()\n",
    "  data_dir = os.path.join(NEMO_ROOT,'data/validation_files_wav')\n",
    "  os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "  # Get the path to the folder containing the audio files\n",
    "  audio_folder_path = './data/validation_files'\n",
    "\n",
    "  # Get a list of all the audio files in the folder\n",
    "  audio_files = glob.glob(audio_folder_path + '/*')\n",
    "\n",
    "  # Read each audio file\n",
    "  for audio_file_path in audio_files:\n",
    "    file_name = audio_file_path[len(audio_folder_path):]\n",
    "    print('Converting: ' + file_name)\n",
    "    wav_path = data_dir + file_name[:-4] + '.wav'\n",
    "    convert_audio_file(audio_file_path, wav_path)\n",
    "\n",
    "  print(\"Finished conversion.\\n******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Speaker Verification to verify the audio files  \n",
    "\n",
    "Input: \n",
    "- audio files should be 16KHz mono channel wav files\n",
    "\n",
    "Output:\n",
    "- True: if two provided audio files are from the same speaker \n",
    "- False: otherwise\n",
    "\"\"\"\n",
    "def speaker_recognition(file_path_1, file_path_2):\n",
    "  speaker_model = nemo_asr_models.EncDecSpeakerLabelModel.from_pretrained(model_name='titanet_large')\n",
    "  decision = speaker_model.verify_speakers(file_path_1, file_path_2)\n",
    "  print(decision)\n",
    "  return decision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - convert validation files\n",
    "\n",
    "# Step 2 - iterate through all wav files and call speaker_recognition\n",
    "# Step 2.a iterate\n",
    "# Step 2.b match names of files to get actual value\n",
    "# Step 2.c call speaker_recognition to get predicted value\n",
    "# Step 2.d print results and write to excel\n",
    "\n",
    "# Step 3 - analyzing magic"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
